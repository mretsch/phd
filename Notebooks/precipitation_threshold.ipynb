{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getuser # Libaray to copy things\n",
    "from pathlib import Path # Object oriented libary to deal with paths\n",
    "import os\n",
    "from tempfile import NamedTemporaryFile, TemporaryDirectory # Creating temporary Files/Dirs\n",
    "from subprocess import run, PIPE\n",
    "import sys\n",
    "from dask.utils import format_bytes\n",
    "import dask # Distributed data libary\n",
    "from dask_jobqueue import SLURMCluster # Setting up distributed memories via slurm\n",
    "from distributed import Client, progress, wait # Libaray to orchestrate distributed resources\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set some user specific variables\n",
    "# scratch_dir = Path('/scratch') / getuser()[0] / getuser() # Define the users scratch dir\n",
    "# # Create a temp directory where the output of distributed cluster will be written to, after this notebook\n",
    "# # is closed the temp directory will be closed\n",
    "# dask_tmp_dir = TemporaryDirectory(dir=scratch_dir, prefix='threshold')\n",
    "# cluster = SLURMCluster(memory='500GiB',\n",
    "#                        cores=72,\n",
    "#                        project='mh0731',\n",
    "#                        walltime='1:00:00',\n",
    "#                        queue='gpu',\n",
    "#                        name='threshold',\n",
    "#                        scheduler_options={'dashboard_address': ':12435'},\n",
    "#                        local_directory=dask_tmp_dir.name,\n",
    "#                        job_extra=[f'-J threshold', \n",
    "#                                   f'-D {dask_tmp_dir.name}',\n",
    "#                                   f'--begin=now',\n",
    "#                                   f'--output={dask_tmp_dir.name}/LOG_cluster.%j.o',\n",
    "#                                   f'--output={dask_tmp_dir.name}/LOG_cluster.%j.o'\n",
    "#                                  ],\n",
    "#                        interface='ib0')\n",
    "# cluster.scale(jobs=1) # requests whole nodesy\n",
    "# dask_client = Client(cluster)\n",
    "# # dask_client.wait_for_workers(18) # gpu-partition has 9 workers per node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/work/mh0731/m300414/DyWinter_b9/Tropics_20to20/Daily')\n",
    "glob_pattern_2d = 'pr_*[0-9].nc'\n",
    " \n",
    "# Collect all file names with pathlib's rglob and list compressions \n",
    "file_names = sorted([str(f) for f in data_path.rglob(f'{glob_pattern_2d}')])[10:] #[1:]\n",
    "# dset = xr.open_mfdataset(file_names)\n",
    "# var_names = ['pr']\n",
    "# da = dset[var_names] #.persist()\n",
    "# da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radar data is in mm/hour and model data in kg/m2s. Conversion factor to get from mm/hour to kg/m2s is 1/3600."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_threshold = 3/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening all consecutive data does not work well later with the numpy-arrays\n",
    "# ds = xr.open_mfdataset(file_names, combine='by_coords', parallel=True) # doesnt want to work, maybe too much although in dask\n",
    "# ds\n",
    "conv_rain = []\n",
    "conv_percentage = []\n",
    "for file in file_names:\n",
    "    rain    = xr.open_dataset(file)['pr']\n",
    "    rain_np = np.asarray(rain)\n",
    "    n_rainy_cells = (rain_np > 0.).sum()\n",
    "    conv_mask     =  rain_np > rain_threshold\n",
    "    n_conv_cells  = conv_mask.sum()\n",
    "    conv_rain.append( rain_np[conv_mask] )\n",
    "    conv_percentage.append( conv_rain[-1].sum() / n_rainy_cells )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_conv = np.concatenate(conv_rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average 0.0041698179858736% of rainy cells are of convective nature, given a rain threshold of 3.0 mm/hour.\n"
     ]
    }
   ],
   "source": [
    "print(f'On average {np.asarray(conv_percentage).mean()*100}% of rainy cells are of convective nature, given a rain threshold of {rain_threshold*3600} mm/hour.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.DataArray(rain_conv).to_netcdf('/work/mh0731/m300414/DyWinter_b9/Tropics_20to20/conv_rain_3mmhour.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 unstable (using the module python3/unstable)",
   "language": "python",
   "name": "python3_unstable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
