{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getuser # Libaray to copy things\n",
    "from pathlib import Path # Object oriented libary to deal with paths\n",
    "import os\n",
    "from tempfile import NamedTemporaryFile, TemporaryDirectory # Creating temporary Files/Dirs\n",
    "from subprocess import run, PIPE\n",
    "import sys\n",
    " \n",
    "import dask # Distributed data libary\n",
    "from dask_jobqueue import SLURMCluster # Setting up distributed memories via slurm\n",
    "from distributed import Client, progress, wait # Libaray to orchestrate distributed resources\n",
    "import xarray as xr # Libary to work with labeled n-dimensional data and dask\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some user specific variables\n",
    "scratch_dir = Path('/scratch') / getuser()[0] / getuser() # Define the users scratch dir\n",
    "\n",
    "# Create a temp directory where the output of distributed cluster will be written to, after this notebook\n",
    "# is closed the temp directory will be closed\n",
    "dask_tmp_dir = TemporaryDirectory(dir=scratch_dir, prefix='threshold_')\n",
    "cluster = SLURMCluster(memory='500GiB',\n",
    "                       cores=72,\n",
    "                       project='mh0731',\n",
    "                       walltime='00:45:00',\n",
    "                       queue='gpu',\n",
    "                       name='threshold',\n",
    "                       scheduler_options={'dashboard_address': ':12435'},\n",
    "                       local_directory=dask_tmp_dir.name,\n",
    "                       job_extra=[f'-J thrshld', \n",
    "                                  f'-D {dask_tmp_dir.name}',\n",
    "                                  f'--begin=now',\n",
    "                                  f'--output={dask_tmp_dir.name}/LOG_cluster.%j.o',\n",
    "                                  f'--output={dask_tmp_dir.name}/LOG_cluster.%j.o'\n",
    "                                 ],\n",
    "                       interface='ib0')\n",
    "\n",
    "cluster.scale(jobs=2) # requests whole nodes\n",
    "dask_client = Client(cluster)\n",
    "dask_client.wait_for_workers(18) # gpu-partition has 9 workers per node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/work/mh0731/m300414/DyWinter_b10/Precip_Flux/')\n",
    "glob_pattern_2d = 'pr_*[0-9]_tropics.nc'\n",
    " \n",
    "# Collect all file names with pathlib's rglob and list compressions \n",
    "# dont take first ten days, they are spin-up\n",
    "file_names = sorted([str(f) for f in data_path.rglob(f'{glob_pattern_2d}')])[10:] #[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200131T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200201T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200202T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200203T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200204T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200205T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200206T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200207T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200208T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200209T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200210T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200211T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200212T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200213T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200214T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200215T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200216T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200217T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200218T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200219T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200220T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200221T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200222T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200223T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200224T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200225T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200226T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200227T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200228T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200229T0000_tropics.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Precip_Flux/pr_20200301T0000_tropics.nc']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radar data is in mm/hour and model data in kg/m2s. Conversion factor to get from mm/hour to kg/m2s is 1/3600."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening all consecutive data does not work well later with the numpy-arrays\n",
    "# ds = xr.open_mfdataset(file_names, combine='by_coords', parallel=True) # doesnt want to work, maybe too much although in dask\n",
    "# ds\n",
    "\n",
    "# rain_threshold_in_mm = 5\n",
    "# rain_threshold       = rain_threshold_in_mm / 3600\n",
    "\n",
    "@dask.delayed\n",
    "def get_convective_rain(file, rain_threshold):\n",
    "    rain          = np.asarray(xr.open_dataset(file)['pr'])\n",
    "    assert rain.shape[1] > rain.shape[0] # second dimension are the myriad of cells, not time\n",
    "    conv_mask     =  rain > rain_threshold\n",
    "    \n",
    "    # everython per time step\n",
    "    n_cells_per_time = rain.shape[1]\n",
    "    conv_area_fraction = conv_mask.sum(axis=1) / n_cells_per_time\n",
    "    avg_conv_rain = np.where(conv_mask, rain, 0.).mean(axis=1)\n",
    "    \n",
    "    # everything for the whole file (time and space)\n",
    "    n_rainy_cells = (rain > 0.).sum() \n",
    "    n_conv_cells  = conv_mask.sum()\n",
    "    conv_rain_pixels    = rain[conv_mask] # boolean indexing of 2d-numpy-array returns just 1d-vector\n",
    "    conv_to_strat_ratio = n_conv_cells / n_rainy_cells\n",
    "    \n",
    "    return (avg_conv_rain , conv_area_fraction)\n",
    "\n",
    "# rain_futures = []\n",
    "# for file in file_names:\n",
    "#     rain_futures.append(get_convective_rain(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring data into distributed memory via persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs = dask.persist(rain_futures)\n",
    "# progress(jobs, notebook=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data(rain_threshold_in_mm):\n",
    "    rain_threshold       = rain_threshold_in_mm / 3600\n",
    "    \n",
    "    rain_futures = []\n",
    "    for file in file_names:\n",
    "        rain_futures.append(get_convective_rain(file, rain_threshold))\n",
    "    \n",
    "    # Bring data into distributed memory via persist()\n",
    "    jobs = dask.persist(rain_futures)\n",
    "    progress(jobs, notebook=False)\n",
    "    \n",
    "    return rain_futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather data into single memory with compute(). Here this acts on data which already was brought into distributed memory via persist(), thus it should be fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_data(futures):\n",
    "    tuples = dask.compute(*futures)\n",
    "\n",
    "    mean_conv_rain, caf = zip(*tuples)\n",
    "\n",
    "    mean_conv_rain     = np.concatenate(mean_conv_rain) * 3600\n",
    "    conv_area_fraction = np.concatenate(caf)\n",
    "    \n",
    "    return mean_conv_rain, conv_area_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'{rain_threshold} should be smaller than {conv_rain.min()}')\n",
    "#print(f'On average {np.asarray(conv_percentage).mean()*100}% of rainy cells are of convective nature, given a rain threshold of {rain_threshold*3600} mm/hour.')\n",
    "\n",
    "#ds = xr.open_dataset(file_names[0])\n",
    "#ds_out = xr.DataArray(conv_rain, name=ds['pr'].name, attrs={**ds['pr'].attrs,**ds.attrs})\n",
    "#ds_out.to_netcdf('/work/mh0731/m300414/DyWinter_b9/Tropics_20to20/conv_rain_8mmhour.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(mean_conv_rain, conv_area_fraction, threshold):\n",
    "    r = np.corrcoef(mean_conv_rain, conv_area_fraction)[0, 1]\n",
    "    plt.hist2d(mean_conv_rain, conv_area_fraction*100, bins=(50, 50))\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('Convective area fraction [%]')\n",
    "    plt.xlabel(\"Domain-average 'convective' rain rate [mm/h]\")\n",
    "    plt.title(f\"'Convective' rain > {threshold:.2f} mm/h, r={r:.2f}\")\n",
    "    plt.savefig(f'/home/mpim/m300414/Plots/caf_convrain_higher{threshold:.2f}.pdf', bbox_inches='tight', transparent=True)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  1min 23.2s\r"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(10, 14, 1)\n",
    "for threshold in thresholds:\n",
    "    dask_futures = run_data(threshold)\n",
    "    conv_rr, caf = gather_data(dask_futures)\n",
    "    plot_data(conv_rr, caf, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 unstable (using the module python3/unstable)",
   "language": "python",
   "name": "python3_unstable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
