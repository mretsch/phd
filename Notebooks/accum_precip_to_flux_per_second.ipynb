{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getuser # Libary to copy things\n",
    "from pathlib import Path    # Object oriented libary to deal with paths\n",
    "import os\n",
    "from tempfile import NamedTemporaryFile, TemporaryDirectory # Creating temporary Files/Dirs\n",
    "from subprocess import run, PIPE\n",
    "import sys\n",
    " \n",
    "import dask # Distributed data libary\n",
    "from dask_jobqueue import SLURMCluster # Setting up distributed memories via slurm\n",
    "from distributed import Client, progress, wait # Libaray to orchestrate distributed resources\n",
    "import xarray as xr # Libary to work with labeled n-dimensional data and dask\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some user specific variables\n",
    "scratch_dir = Path('/scratch') / getuser()[0] / getuser() # Define the users scratch dir\n",
    "\n",
    "# Create a temp directory where the output of distributed cluster will be written to, after this notebook\n",
    "# is closed the temp directory will be closed\n",
    "dask_tmp_dir = TemporaryDirectory(dir=scratch_dir, prefix='accum2flux_')\n",
    "\n",
    "cluster = SLURMCluster(memory='500GiB',\n",
    "                       cores=72,\n",
    "                       project='mh0731',\n",
    "                       walltime='1:00:00',\n",
    "                       queue='gpu',\n",
    "                       name='accum2flux',\n",
    "                       scheduler_options={'dashboard_address': ':12435'},\n",
    "                       local_directory=dask_tmp_dir.name,\n",
    "                       job_extra=[f'-J accm2flx', \n",
    "                                  f'-D {dask_tmp_dir.name}',\n",
    "                                  f'--begin=now',\n",
    "                                  f'--output={dask_tmp_dir.name}/LOG_cluster.%j.o',\n",
    "                                  f'--output={dask_tmp_dir.name}/LOG_cluster.%j.o'\n",
    "                                 ],\n",
    "                       interface='ib0')\n",
    "\n",
    "cluster.scale(jobs=2)\n",
    "dask_client = Client(cluster)\n",
    "dask_client.wait_for_workers(18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def accumulation_to_flux(present_file, previous_file):\n",
    "    \n",
    "    data         = xr.open_mfdataset( present_file)['tp']\n",
    "    data_earlier = xr.open_mfdataset(previous_file)['tp']\n",
    "    # to assign values to dask-array, first load it to memory\n",
    "    data.load()\n",
    "    \n",
    "    # the short time steps (15 minutes) inside one file\n",
    "    n_minutes = 15\n",
    "    data[{'time': slice(1, None)}] = (data[{'time': slice(1, None)}].values - data[{'time': slice(None, -1)}].values) / (n_minutes * 60)\n",
    "        \n",
    "    # the long time step (30 minutes) across two files, because the midnight value is stored in neither file\n",
    "    n_minutes = 30\n",
    "    data[{'time': 0}] = (data[{'time': 0}].values - data_earlier[{'time': -1}].values) / (n_minutes * 60)\n",
    "    \n",
    "    # adjust attributes\n",
    "    data.attrs['units'] = 'kg m**-2 s**-1'\n",
    "    data.attrs['long_name'] = 'Precipitation flux'\n",
    "    data.name = 'pr'\n",
    "    \n",
    "    # write results to disk\n",
    "    date = present_file[-24:-11]\n",
    "    outfile = Path('/work/mh0731/m300414/') / 'DyWinter_b10' / 'Precip_Flux' / f'pr_{date}_tropics.nc'\n",
    "    data.to_netcdf(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/work/mh0731/m300414/DyWinter_b10/Tropics_fromGrib/')\n",
    "glob_pattern = 'tp_'\n",
    "# if dont take first element(s), theres a subdir with more matching files, we dont want that\n",
    "data_files = sorted([str(f) for f in data_path.rglob(f'*{glob_pattern}*.nc')]) #[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200220T0000\n",
      "20200221T0000\n",
      "20200222T0000\n",
      "20200223T0000\n",
      "20200224T0000\n",
      "20200225T0000\n",
      "20200226T0000\n",
      "20200227T0000\n",
      "20200228T0000\n",
      "20200229T0000\n",
      "20200301T0000\n"
     ]
    }
   ],
   "source": [
    "run_futures = []\n",
    "for previous_file, present_file in zip(data_files[30:], data_files[31:]):\n",
    "    \n",
    "    print(present_file[-24:-11])\n",
    "    \n",
    "    run_futures.append( accumulation_to_flux(present_file=present_file, previous_file=previous_file) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  2min 26.2s\r"
     ]
    }
   ],
   "source": [
    "run_jobs = dask.persist(run_futures)\n",
    "progress(run_jobs, notebook=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 unstable (using the module python3/unstable)",
   "language": "python",
   "name": "python3_unstable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
