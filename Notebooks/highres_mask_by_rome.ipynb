{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getuser # Libaray to copy things\n",
    "from pathlib import Path # Object oriented libary to deal with paths\n",
    "import os\n",
    "from tempfile import NamedTemporaryFile, TemporaryDirectory # Creating temporary Files/Dirs\n",
    "from subprocess import run, PIPE\n",
    "import sys\n",
    " \n",
    "import dask # Distributed data libary\n",
    "from dask_jobqueue import SLURMCluster # Setting up distributed memories via slurm\n",
    "from distributed import Client, progress, wait # Libaray to orchestrate distributed resources\n",
    "\n",
    "import xarray as xr # Libary to work with labeled n-dimensional data and dask\n",
    "import numpy as np\n",
    "import skimage.util as sutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sys.path.insert(0, os.path.abspath('/home/mpim/m300414/phd/'))\n",
    "from org_metrics import Pairs, gen_regionprops_objects_all, gen_shapely_objects_all, gen_tuplelist\n",
    "from org_metrics import radar_organisation_metric, avg_area, lower_rom_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.50.40.25:38826</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.50.40.25:12435/status' target='_blank'>http://10.50.40.25:12435/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>18</li>\n",
       "  <li><b>Cores: </b>144</li>\n",
       "  <li><b>Memory: </b>1.07 TB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.50.40.25:38826' processes=18 threads=144, memory=1.07 TB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set some user specific variables\n",
    "scratch_dir = Path('/scratch') / getuser()[0] / getuser() # Define the users scratch dir\n",
    "\n",
    "# Create a temp directory where the output of distributed cluster will be written to, after this notebook\n",
    "# is closed the temp directory will be closed\n",
    "dask_tmp_dir = TemporaryDirectory(dir=scratch_dir, prefix='dive_')\n",
    "cluster = SLURMCluster(memory='500GiB',\n",
    "                       cores=72,\n",
    "                       project='mh0731',\n",
    "                       walltime='03:20:00',\n",
    "                       queue='gpu',\n",
    "                       name='dive',\n",
    "                       scheduler_options={'dashboard_address': ':12435'},\n",
    "                       local_directory='/home/mpim/m300414/phd/Notebooks/',\n",
    "                       job_extra=[f'-J dive', \n",
    "                                  f'-D /home/mpim/m300414/phd/Notebooks/',\n",
    "                                  f'--begin=now',\n",
    "                                  f'--output={dask_tmp_dir.name}/LOG_cluster.%j.o',\n",
    "                                  f'--output={dask_tmp_dir.name}/LOG_cluster.%j.o'\n",
    "                                 ],\n",
    "                       interface='ib0')\n",
    "\n",
    "cluster.scale(jobs=2) # requests whole nodes\n",
    "dask_client = Client(cluster)\n",
    "dask_client.wait_for_workers(18) # gpu-partition has 9 workers per node\n",
    "# dask_client = Client()\n",
    "dask_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200131T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200201T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200202T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200203T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200204T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200205T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200206T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200207T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200208T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200209T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200210T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200211T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200212T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200213T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200214T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200215T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200216T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200217T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200218T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200219T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200220T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200221T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200222T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200223T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200224T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200225T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200226T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200227T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200228T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200229T0000_reggrid.nc',\n",
       " '/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/div900_20200301T0000_reggrid.nc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rome = xr.open_dataarray('/work/mh0731/m300414/DyWinter_b10/RadarDomain_Grid/rome_14mmhour.nc')\n",
    "\n",
    "data_path = Path('/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/')\n",
    "glob_pattern_2d = 'div900_*.nc'\n",
    " \n",
    "# Collect all file names with pathlib's rglob and list compressions \n",
    "file_names = sorted([str(f) for f in data_path.rglob(f'{glob_pattern_2d}')])[-31:]\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref = xr.open_dataarray('/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/rh500_20200227T0000_reggrid.nc')\n",
    "# ref_lat = ref['lat']\n",
    "# ref_lon = ref['lon']\n",
    "# for f in file_names:\n",
    "#     ar = xr.open_dataarray(f)\n",
    "#     ar['lat'] = ref_lat\n",
    "#     ar['lon'] = ref_lon\n",
    "#     ar.to_netcdf(f'/work/mh0731/m300414/DyWinter_b10/{f[-31:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def mask_highres_by_coarse(bool_coarse, highres_mask):\n",
    "\n",
    "    domain_size = (117, 117)\n",
    "    half_size = domain_size[0] // 2\n",
    "    assert domain_size[0]     == domain_size[1] # domain is quadratic\n",
    "    assert domain_size[0] % 2 == 1              # number of pixels is not even\n",
    "    \n",
    "    bool_stack = bool_coarse.stack({'z': ('lat', 'lon')})\n",
    "    \n",
    "    # get indices of high-res field (via argsort()) where boolean is true\n",
    "    lat_indices = highres_mask['lat'].argsort().sel({'lat': bool_stack[bool_stack]['lat'].values})\n",
    "    lon_indices = highres_mask['lon'].argsort().sel({'lon': bool_stack[bool_stack]['lon'].values})\n",
    "\n",
    "    # get all the other indices of the high-res field, surrounding the indices derived from the coarse field\n",
    "    lat_ind_list = []\n",
    "    lon_ind_list = []\n",
    "    for i in range(-half_size, half_size + 1):\n",
    "        for j in range(-half_size, half_size + 1):\n",
    "\n",
    "            lat_ind_list.append((lat_indices + i).values)\n",
    "            lon_ind_list.append((lon_indices + j).values)\n",
    "            \n",
    "    del lat_indices, lon_indices\n",
    "\n",
    "    # swap grouping of the selected indices\n",
    "    transpose_lat_ind_list = list(zip(*lat_ind_list))\n",
    "    transpose_lon_ind_list = list(zip(*lon_ind_list))\n",
    "    \n",
    "    del lat_ind_list, lon_ind_list\n",
    "    \n",
    "    # concatenate all the indices, needed for slicing the DataArray later\n",
    "    raw_lat_ind_list = []\n",
    "    raw_lon_ind_list = []\n",
    "    for lat_tup, lon_tup in zip(transpose_lat_ind_list, transpose_lon_ind_list):\n",
    "        raw_lat_ind_list.extend(list(lat_tup))\n",
    "        raw_lon_ind_list.extend(list(lon_tup))\n",
    "        \n",
    "    del transpose_lat_ind_list, transpose_lon_ind_list\n",
    "    \n",
    "    # get actual lat/lon-values, based on indices. For cyclic longitudes we need modulo-operation.\n",
    "    lat_select = highres_mask['lat'][         raw_lat_ind_list                            ].values\n",
    "    lon_select = highres_mask['lon'][np.array(raw_lon_ind_list) % len(highres_mask['lon'])].values\n",
    "\n",
    "    del raw_lat_ind_list, raw_lon_ind_list\n",
    "    \n",
    "    # zip the selected lat/lon together, to mimic the stacked dimension, and get unique pairs via a set.\n",
    "    lat_lon_unique = list(set(zip(lat_select, lon_select)))\n",
    "    \n",
    "    highres_stack = highres_mask.stack({'k': ('lat', 'lon')}).copy()\n",
    "    del highres_mask\n",
    "    \n",
    "    highres_stack.loc[dict(k=lat_lon_unique)] = True\n",
    "\n",
    "    return highres_stack.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200131T0000\n",
      "20200201T0000############################] | 100% Completed |  2min 20.3s\n",
      "20200202T0000############################] | 100% Completed |  2min 35.0s\n",
      "20200203T0000############################] | 100% Completed |  2min 24.6s\n",
      "20200204T0000############################] | 100% Completed |  2min 39.3s\n",
      "20200205T0000############################] | 100% Completed |  2min 39.3s\n",
      "20200206T0000############################] | 100% Completed |  2min 52.0s\n",
      "20200207T0000############################] | 100% Completed |  2min 52.9s\n",
      "20200208T0000############################] | 100% Completed |  2min 55.5s\n",
      "20200209T0000############################] | 100% Completed |  2min 58.1s\n",
      "20200210T0000############################] | 100% Completed |  2min 58.5s\n",
      "20200211T0000############################] | 100% Completed |  2min 58.0s\n",
      "20200212T0000############################] | 100% Completed |  2min 52.3s\n",
      "20200213T0000############################] | 100% Completed |  3min 14.2s\n",
      "20200214T0000############################] | 100% Completed |  3min 20.2s\n",
      "20200215T0000############################] | 100% Completed |  3min 14.1s\n",
      "20200216T0000############################] | 100% Completed |  3min 39.1s\n",
      "20200217T0000############################] | 100% Completed |  3min 25.4s\n",
      "20200218T0000############################] | 100% Completed |  3min 39.9s\n",
      "20200219T0000############################] | 100% Completed |  3min 43.5s\n",
      "20200220T0000############################] | 100% Completed |  3min 36.6s\n",
      "20200221T0000############################] | 100% Completed |  3min 38.3s\n",
      "20200222T0000############################] | 100% Completed |  3min 18.6s\n",
      "20200223T0000############################] | 100% Completed |  3min 26.9s\n",
      "20200224T0000############################] | 100% Completed |  3min  0.8s\n",
      "20200225T0000############################] | 100% Completed |  3min  7.5s\n",
      "20200226T0000############################] | 100% Completed |  3min 34.6s\n",
      "20200227T0000############################] | 100% Completed |  2min 57.9s\n",
      "20200228T0000############################] | 100% Completed |  3min 15.4s\n",
      "20200229T0000############################] | 100% Completed |  2min 50.6s\n",
      "20200301T0000############################] | 100% Completed |  3min  4.0s\n",
      "[########################################] | 100% Completed | 35.0s\r"
     ]
    }
   ],
   "source": [
    "for file in file_names:\n",
    "    date = file[-24:-11]\n",
    "    print(date)\n",
    "\n",
    "    var_to_process = xr.open_mfdataset(file)['div']\n",
    "\n",
    "    l_rome_p90 = (rome > np.nanpercentile(rome, q=90))\n",
    "    highres_mask = xr.full_like(var_to_process, fill_value=False, dtype='bool')\n",
    "\n",
    "    # parallelisation on time level\n",
    "    map_singletime = []\n",
    "    for t in highres_mask.time:\n",
    "        coarse_mask = l_rome_p90.sel(time=str(t.values), method='nearest')\n",
    "        map_singletime.append( mask_highres_by_coarse(coarse_mask, highres_mask.sel(time=str(t.values)) ))\n",
    "    \n",
    "    jobs = dask.persist(map_singletime)\n",
    "    progress(jobs, notebook=False)\n",
    "\n",
    "    result = xr.concat(dask.compute(*map_singletime), dim=var_to_process.time)\n",
    "\n",
    "    result.name = 'high_rome_mask'\n",
    "    result.attrs['units'] = '1'\n",
    "    result.attrs['long_name'] = 'Mask for 90perc-ROME across (117*2.5)x(117*2.5) km domain.'\n",
    "\n",
    "    result.to_netcdf(f'/work/mh0731/m300414/DyWinter_b10/Cartesian_Grid/rome90p_{date}_mask.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 unstable (using the module python3/unstable)",
   "language": "python",
   "name": "python3_unstable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
